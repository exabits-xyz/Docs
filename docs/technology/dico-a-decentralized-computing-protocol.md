---
sidebar_position: 2
---

import useBaseUrl from '@docusaurus/useBaseUrl';

# DiCo — A Decentralized Computing Protocol

<div className="image-content">
    <div className="image-block">
        <img
        src={useBaseUrl('./img/assets/images/dico-a-decentralized-1.webp')}
        alt="DiCo — A Decentralized Computing Protocol"
        />
    
    </div>
</div>

During the first era of the internet — from the late 1960s through the early 2000s — internet services were built on open protocols that were controlled by the internet community. During the second era of the internet, from the mid-2000s to the present, end-users establish a connection to a website like Twitter.com and log in to the service and keep all their data with the remote service. This model, along with advances in cloud computing, pushes users to migrate from open services to these more sophisticated, centralized services. The things we do on the internet daily are controlled by just a few giants. 4 companies control over 70% of the world’s cloud infrastructure. This is a full departure from the spirit of a decentralized internet where end-users have the full sovereignty of the data and logic.

We release users from these monopolies by proposing a decentralized computing protocol, called DiCo, which enables users to access a decentralized computing network. Users can access apps and services by using decentralized identity (DID) and process data generated by apps/services on backends owned by the user (instead of the service provider). Our design philosophy is to use blockchain-based secure hardware, called Trusted Computing Node (TCN), in a way that end-users do not need to trust the underlying nodes. Trusted Execution Environments (TEE), such as Intel Software Guard Extensions (SGX) or AMD Secure Memory Encryption (SME) and Secure Encrypted Virtualisation (SEV), can be used to provide trusted computing environments. The TCN implementation is trusted to be correct and secure, which can be decentralized and audited. The TCN stores encrypted and/or signed data and perform computing services orchestrated by blockchain. A TCN has no visibility into the user’s data and can only see encrypted data chunks. In addition, a TCN cannot tamper with user data since the associated public keys or data hashes are discoverable through the blockchain channel.

Instead of connecting to a central point, DiCo is designed to be a service-oriented platform where communication is driven by service names rather than fixed addresses. A service name corresponds to a group of (possibly changing) processes offering the same service. Applications can use names to directly express their intent to publish or access specific services. This elevates services to first-class network entities (distinct from a centralized host or interface) that can be dynamic and hosted by decentralized TCNs.

At the core of DiCo is a new Service Access Network (SAN) that maps service names in packets to network addresses, based on rules in its service table managed by a blockchain (explained further below). The SAN can be programmed through a user-space control plane acting on service-level events. This gives network programmers hooks for ensuring service-resolution systems are up-to-date.

Decentralized applications (Dapps) can publish/subscribe services to/from DiCo. The DiCo stack offers a clean service-level control/data plane split: the user-space service orchestrator can manage service resolution based on policies, listen for service-related events, monitor service performance, and communicate with other orchestrators; the SAN provides a service-level data plane responsible for connecting to services through forwarding over service tables. Once connected, the SAN maps the new flow to its socket in the flow table, ensuring incoming packets can be demultiplexed. Connectivity can be maintained across physical mobility, virtual migration, and churn of TCN. Dapps interact with the stack via name-based sockets that tie socket calls (e.g., bind and connect) directly to service-related events in the stack. These events cause updates to the data-plane state and are also passed up to the control plane (which subsequently may use them to update resolution and registration systems).

As such, DiCo gives service providers more control over service access, and clients more flexibility in resolving services. For instance, by forwarding the first packet of a connection based on the service name, the SAN can defer binding a service until the packet reaches the part of the network with fine-grain, up-to-date information. This ensures more efficient load balancing and faster failover. The rest of the traffic flows directly between end points according to network-layer forwarding. The SAN performs signaling between end-points to establish additional flows (over different interfaces or paths) and can migrate them over time. In doing so, the SAN provides a transport-agnostic solution for TCN failover.

To handle a wide range of services and deployment scenarios, the blockchain disseminates serviceID prefixes (hashed names) to DiCo, while the SAN applies rules to packets, sending them onward — if necessary, through service routers deeper in the network — to remote service instance. The SAN does not control which forwarding rules are in the service table, when they are installed, or how they propagate to other TCNs. Instead, the local service controller (i) manages the state in the service table and (ii) potentially propagates it to other service orchestrators. DiCo is responsible for registering, resolving, and routing services, which supports distributed service deployment scenarios.

## Service Registration

DiCo maintains a service naming system as a separate logical layer on top of the underlying blockchain on which it operates. DiCo uses the underlying blockchain to achieve consensus on the state of this naming system and bind services to providers.

In the aspect of resource management, the orchestration layer achieves information from the resource layer and manages the life cycle of TCNs from beginning to end. The employment of computing resources and network resources is conducted through the orchestration layer, with metadata stored in the network layer and pointers sent to the blockchain.

Blockchains have limited bandwidth with the unacceptable worst-case performance of lookups. The solution is to perform service registration off-chain, generate a proof, and send the proof on-chain. Currently, DiCo uses S/Kademlia distributed hash table (DHT) for service operations (registration, resolution, and routing). S/Kademlia is a structured peer network that avoids a number of known attacks in the traditional Kademlia network. Nodes in the peer network maintain a connection to a subset of other peers on the network. The S/Kademlia stores service files for SAN that are identical to DNS zone files. Pointers to specific services are stored service files managed by the peer network, while the actual services are hosted on computing backends (TCNs). The peer nodes are programmed not to accept service file writes unless a hash of the service is present in the blockchain.

Separation of the Control and Service Plane: DiCo decouples the security of name registration and name ownership from the availability of data associated with names by separating the control and data planes. The control plane defines the protocol for registering services (identified by service names), creating (service, hash) bindings, and creating bindings to owning cryptographic keypairs, which is a logically separate layer on top.

The service plane is responsible for storing service information, mainly the service-hash pairs. It consists of (a) service files for discovering service by hash or URL and (b) external storage systems for storing service information. Service names are signed by the public keys of the respective service owners. Devices receive services from the service plane and verify their authenticity by checking that either the services hash is in the service file, or the service includes a signature with the name owner’s public key.

## Service Resolution

Services are resolved through the peer network. A hash-based serviceID is forwarded through service tables distributedly maintained by SAN, ultimately registering or resolving with a node responsible for the serviceID. This resolution can coexist with an IANA-controlled resolution hierarchy, however, as both simply map to different rules in the same service table.

DHTs such as Kademlia require multiple network round trips for many operations, which is difficult to achieve millisecond-level response times. To speed up the response time, we add a basic decentralized caching service on top of the peer network. The caching service will live independently in each peer node and attempt to talk to every TCN in the network periodically. The caching service will then cache the last known good address for each TCN, and delist nodes that it has not talked to after a certain period of time. TCNs do not need to know about the caching services. We expect the caching service to scale for the reasonable future, as ping operations are inexpensive, but admit a new solution may ultimately be necessary. Generally, space requirements are acceptable. For example, caching for a network of 500K TCNs can be done with around 35MB of memory.

With each Kademlia message shared on the network, nodes will include their available disk space, per-node bandwidth availability, wallet address, and any other meta-data the network needs. The service resolution cache will collect this information provided by the nodes, allowing faster lookups.

The S/Kademlia DHT is used for the pilot implementation, but may not be ultimate. We believe that the industry is still relatively young and evolving, and it is too early to pick a winning DHT technology. It is hard to predict which DHT technology will be operational and reliable five years from now. The modular structure of DiCo provides full compatibility with new DHT technologies, which enables the system to be self-evolved.

## Service Routing

The service files stored in the peer network serve as pointers to the TCN that provides the computing service. The route to the service is returned by the blockchain to the subscriber. When the previous service provider moves or gets churn (which can be quickly discovered by the DiCo stack), the route for the particular service is redirected to an alternative provider. Meanwhile, the service file of the previous service provider is updated. In such a manner, DiCo supports ubiquitous mobility and service migration handling node churns.

The peer network only stores service files if the service was previously announced in the blockchain. This effectively whitelists the service that can be hosted by DiCo. The key aspect relevant to the design of DiCo is that routes (irrespective of where they are fetched from) can be verified and therefore cannot be tampered with. Further, most production servers that can be used by peer nodes maintain a full copy of all service files since the size of service files is relatively small. Keeping a full copy of routing data introduces only a marginal storage cost on top of storing the blockchain data.
