---
sidebar_position: 1
---

import useBaseUrl from '@docusaurus/useBaseUrl';

# A Mutual Computing Network Stack

<div className="image-content">
    <div className="image-block">
        <img
        src={useBaseUrl('./img/assets/images/a-mutual-computing-network-stack-1.webp')}
        alt="A Mutual Computing Network Stack"
        />
    
    </div>
    <div className="image-block-alt">
        Credit: Eduard Muzhevskyi/iStock/Getty Images Plu
    </div>
</div>

Current cloud services can be costly, with questionable security. We present the design and implementation of a Mutual Computing Network Stack (MCNS) where users do not need to trust remote data centers. We remove any trust points from the middle of the network and leverage blockchains to secure critical service bindings. MCNS implements services for identity, discovery, and storage and can survive failures of distributed computing nodes. MCNS gives comparable performance to traditional cloud services and enables a much-needed security and reliability upgrade to the traditional cloud.

The MCNS architecture is based on the ubiquity of internet access, which interlinks the dynamic distribution and consolidated collaborative scheduling through multi-dimensional resources such as networking, storage, and computing. This enables bulks of applications to call computing resources upon request. In this way, the global optimization of network connection is realized, providing users with a consistent experience. In this article, the essentials and technical connotations of the computing network will be discussed, including its network architecture and inter-layer connector. The system which consists of a series of technical points such as controlling, transmitting, arranging, scheduling, resource modeling, service, and transaction, will be elaborated as well.

MCNS consists of the collaborative scheduling of the control panel in calculating the network, the network fusion perception, and the arrangement of computing resources at managerial and service levels. The overall architecture of the computing network system is supposed to be embedded with the capability of unified management of computing resources, storage resources, and network resources. In addition, this architecture should be able to measure the underlying infrastructure resource with a unified standard. Then, load in a network packet with abstract information and share them through the network. In the current computing network system, the capacity of providing users with visualized modules and services should also be taken into consideration. Along with targeting to realize the visualization of arrangement, dispatch, and application through the network interface access of service level and underlying resource.

The computing network can be categorized according to functional levels. These can be roughly divided into the service-providing layer, service arrangement layer, network control layer, computing management layer, computing resource layer, and network transmission layer. The detailed description of each functional layer is as follows:

## Service Layer

The Service layer aims to realize the opening of service capability toward users. By calling the atomic function and service (such as load distribution and AI algorithm in the orchestration layer), users are enabled to define business services in their own applications. As for some functions and algorithms used in business and service, the service-providing layer directly handles them and feedback to users. The function arrangement of the service layer needs to be accomplished through the orchestration layer indirectly, while the calling of the atomic function is accomplished directly through the interface of the service layer.

The service layer captures computing resources and network resource information through a southbound interface from the network layer, enabling the information processing of this layer. While giving feedback to users, the service layer delivers processed intermediate data or other necessary information to network control.

## Orchestration Layer

The Orchestration layer oversees the dispatch, distribution, and life cycle of service resources — including the computing power, container, and network. The effect of service arrangement in the whole computing network equals a decentralized control unit. It issues arrangement instructions through interfaces between each layer and captures returned information. Finally, it sends back information to users.

Concerning resource synergy, the orchestration layer saves current resources, which include computing resources and network resources.
When there is a change in resource status, the orchestration layer is able to capture the corresponding information and update the local resource status. When there is a shift in the need for resources, the orchestration layer allocates dynamically according to the resource status then, ensuring users’ employment of computing resources. When there is a change as a result of underlying resource malfunction, the orchestration layer modifies according to resource status.

In the aspect of resource management, the orchestration layer needs information support from the resource layer. Besides, the orchestration layer is responsible for the life cycle management of resources from beginning to end. The employment of computing resources and network resources by the upper layer can only be conducted through the orchestration layer, not through the traditional approach of a direct configuration of the operating system or command line.

Moving on to process management, the orchestration layer possesses DevOps system management ideas toward application services. This enhances the communication among IT, CT, and OT technical personnel. Users’ needs for atomic functions or services offered by the service layer are entered from the orchestration layer while computing resources and network resources are offered by the orchestration layer as the exit. Meanwhile, the monitoring and management of various resources can be realized through the orchestration layer as well. It is a form of computing as a commodity trading platform. In addition, the orchestration layer should also possess the capability of computing flow and process monitoring of application deployment.

In safety management, the orchestration layer has the capability to authenticate users and resources with the help of blockchain. There is also a mechanism for security checks through the orchestration layer: to recognize whether users can realize capability invocation of the computing network system, and employ the computing resource, as well as the network resource in the resource pool. The orchestration layer can prioritize users and resources. For example, it allows a specific type of user to access prioritized computing resources through authentication by smart contracts. By contrast, unauthorized users or resources are forbidden in interactive functions or just given limited capabilities.

## Network Layer

The Network layer realizes the interlink, distribution, addressing, configuration, and optimization of computing information resources, mainly through the control panel. The network layer functions as a connecting link between the preceding and the following. It is not only responsible for the information collection and distribution of the underlying layer resource information but also responsible for providing network service for the upper layer. Meanwhile, it delivers the latest network control layer information and overall computing information when there is a need for the orchestration layer to interact with the network layer.

Computing resources come from the resource layer and it needs to be connected to the network layer in order to disseminate. As the carrier of information, the network protocol message defines the new link status of the data message (OSPF protocol) according to the measurement value. This comes after the computing information resource modeling or adopting the TLV approach (ISIS protocol) to load the intrinsic protocol message. In this way, the connection between computing information and the network layer is realized.

Once the computing information is interlinked, the network layer needs to synchronize computing information to the whole network. Since the computing information is carried in the network protocol message, the synchronization of computing information must be done after the establishment of the network protocol’s neighbor. Therefore, the change of computing information does not only change when its own resource changes, but also changes according to the status of its network neighbor. This type of change synchronizes in the whole network through the distribution of network protocol messages. The common protocols used in the network layer are IGP protocol which includes RIP, OSPF, ISIS, and EIGRP as well as BGP protocol. Among these protocols, the IGP protocol is responsible for network information synchronization between autonomous systems. In order to achieve synchronization within and between autonomous systems, the computing information needs to extend the IGP protocol and BGP protocol. However, the specific implementation details are still at the stage of research in IETF.

The ultimate target of the computing information interlink and the whole network information synchronization is to achieve the selection, configuration, and optimization of the network path based on computing. Traditional network protocols calculate the shortest computing tree according to link cost to obtain the optimal path to the destination node. Whereas the computing network realizes the selection of the optimal path through the network path calculation based on computing information. For instance, the computing network will direct the calculation of the path based on GPU computing information when the computing capacity needed for a specific video comes from the GPU. Users will not choose the link even if the cost is comparatively less than the specific CPU resource. When there is a change in computing information in a network, the computing network path changes in accordance with the update of information on the whole network. If there is a need to achieve load balancing, it can be completed in the network layer. Additionally, it possesses the characteristics of high efficiency and low latency compared to the load balancing of its corresponding layer.

## Control Layer

The control layer is a functional layer that oversees computing management built by blockchain. This layer is responsible for the registering and modeling of isomeric computing resources, as well as supporting upper computing. Isomeric computing resources are categorized as CPU, GPU, and NPU according to the field of expertise of chips. CPU (Central Processing Unit) deals with general calculation, while GPU (Graphics Processing Unit) specializes in processing image computing. NPU (Network Processing Unit) mainly accelerates the processing of neural network-related computing. These different types of computing resources should be released through the network layer, and they should be registered in the control layer. The registration is to enable the network layer to sense the computing resource and to carry out appropriate quantification. There is also a need for unified modeling in combination with network layer dispatch. This equips various types of processor resources with reasonable dispatching, to be assigned the task that suits them best. Consequently, isomeric computing resources are well organized according to their functions and their duties are well performed.

In addition, the control layer is responsible for supporting the computing transactions and the computing services. Transactions are based on the blockchain’s decentralization, low-cost, reliable, privacy-protected computing transaction platform, and the management of the computing management layer. When there is a demand from the computing users, they are able to sign and bill a contract, record it in the blockchain, and complete the distributed saving through computing trade contracts of the blockchain. Therefore, the control layer is a decentralized deployment architecture. During the process of computing trade, the computing contributor and user are separated. The economical, efficient, and decentralized computing service is provided to the computing users through expandable blockchain technology and container technology, as well as the integration of contributors’ scattered computing.

## Resource Layer

The resource layer oversees the maintenance of all kinds of isomeric computing and network resources. In a narrow sense, this layer includes CPU, GPU, and NPU processors which are mainly used for their computing capabilities. In a broad sense, this layer includes various kinds of independent storage and network resources, as well as the devices which possess data processing capabilities from operating system localization. From the device perspective, the resource layer includes servers, storage, and other commonly used cloud computing equipment. And also contains cars, handheld terminals, drones, and other computing, providing end-side equipment in the future internet of things scenario.

Network transmission modules leverage the SDN network architecture. It oversees the gathering of computing resources and network resources as well as the integration of the physical architecture of various devices. For the management and deployment of resources and devices, the blockchain and orchestration layer is needed for guidance and function as the infrastructure level in the whole computing network system.

In MCNS, the resource layer is compatible with the SDN and NFV technology at the maximum level. On this basis, the capability of pulling through the network control and service arrangement, as well as the realization of synergy between SDN and NFV protocols are achieved. In addition, the target architecture of Metro Fabric is accomplished by extending the Fabric network architecture from the data center to WAN. Meanwhile, the introduction of the resource layer into the whole architecture solves the management, modeling, and transaction functions toward isomeric computing resources. This enables the inter-flow between computing management and network control. Through network connectors, computing management interacts with virtual resources of the orchestration layer in the realization of the deployment of heterogeneous hardware. Network transmission and computing resources are merged to reflect the trend of convergences between computing and network resources.

Additionally, the customized targeted service is also realized among computing resource providers, service providers, and service consumers in the computing network architecture. The computing resource provider opens ability mainly through the blockchain while the computing service provider and computing service consumer open ability mainly through the orchestration layer and service layer. For business-specific providers and consumers, MCNS can offer them decentralized cloud resources. For the computing resource providers and consumers, it is possible to build a blockchain system to satisfy the sharing and transaction of computing demand as well as the realization of elaborated regulations for computing.

Network capabilities take SRv6 as a pedestal to be compatible with computing pooling and other modes. This evolves into serverless application services and meshes service governance with unified management and control of computing resources.
